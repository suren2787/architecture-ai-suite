# ===================================================================
# OpenWebUI Configuration Example
# ===================================================================
# Use this if your organization uses OpenWebUI as a proxy to LLMs
# This is common in corporate environments where direct access to
# Bedrock/OpenAI is blocked by network policies.

# ===================================================================
# LLM Provider Configuration
# ===================================================================
MODEL_PROVIDER=openwebui
# Model name should match what's available in your OpenWebUI instance
# Common options: gpt-4, gpt-3.5-turbo, claude-3-sonnet, deepseek-r1
MODEL_NAME=gpt-4

# ===================================================================
# OpenWebUI Configuration
# ===================================================================
# Base URL of your OpenWebUI instance's API endpoint
# Typically: http://your-server:8080/api/v1 or https://openwebui.yourcompany.com/api/v1
OPENWEBUI_BASE_URL=http://localhost:8080/api/v1

# API key (optional - some OpenWebUI instances don't require authentication)
# Get this from your OpenWebUI instance settings
OPENWEBUI_API_KEY=sk-your-openwebui-api-key

# ===================================================================
# Embeddings Configuration
# ===================================================================
# Use OpenWebUI for embeddings as well
EMBEDDING_PROVIDER=openwebui
# Model name should match what your OpenWebUI provides
# Common: text-embedding-3-small, text-embedding-ada-002
EMBEDDING_MODEL=text-embedding-3-small

# ===================================================================
# Confluence Integration (Optional)
# ===================================================================
CONFLUENCE_EMAIL=your-email@company.com
CONFLUENCE_API_TOKEN=your-confluence-api-token
CONFLUENCE_BASE_URL=https://yourcompany.atlassian.net/wiki

# ===================================================================
# Notes for OpenWebUI Setup
# ===================================================================
# 1. Make sure your OpenWebUI instance is accessible from where you're running this app
# 2. The model names (MODEL_NAME, EMBEDDING_MODEL) must exactly match what's configured in OpenWebUI
# 3. If OpenWebUI is behind your company VPN, ensure you're connected
# 4. Test connectivity: curl http://your-openwebui:8080/api/v1/models
# 5. Some OpenWebUI deployments use different API paths - adjust OPENWEBUI_BASE_URL accordingly
