# ===================================================================
# LLM Provider Configuration (Model-Agnostic)
# ===================================================================
# Choose your LLM provider: 'bedrock', 'openai', or 'anthropic'
MODEL_PROVIDER=bedrock

# Specify the model name/ID for your chosen provider
# Examples:
#   Bedrock: us.deepseek.r1-v1:0, anthropic.claude-v2, anthropic.claude-3-sonnet-20240229-v1:0
#   OpenAI: gpt-4, gpt-3.5-turbo, gpt-4-turbo
#   Anthropic: claude-3-opus-20240229, claude-3-sonnet-20240229
MODEL_NAME=us.deepseek.r1-v1:0

# ===================================================================
# AWS Bedrock Configuration (Required if MODEL_PROVIDER=bedrock)
# ===================================================================
AWS_ACCESS_KEY_ID=your_access_key_here
AWS_SECRET_ACCESS_KEY=your_secret_key_here
AWS_REGION=us-east-1

# ===================================================================
# OpenAI Configuration (Required if MODEL_PROVIDER=openai)
# ===================================================================
# OPENAI_API_KEY=sk-your-api-key-here

# ===================================================================
# Anthropic Configuration (Required if MODEL_PROVIDER=anthropic)
# ===================================================================
# ANTHROPIC_API_KEY=sk-ant-your-api-key-here
